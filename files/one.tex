%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%       Chapter 1
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}
\label{one}

Nowadays Single Instruction Multiple Data (SIMD) instructions are broadly built in for most commodity processors. Compared with the traditional Single Instruction Single Data (SISD) instructions, it provides intra-register level of parallel computing by performing the same operation on many elements at the same time. SIMD instructions becomes more and more popular in the area of multimedia processing, digital signal processing or other compute-intensive applications \cite{hua_idisa}.

A recent method of parallel bit streams (Parabix) that shows promises in paralleling text processing uses SIMD operations for speed up. It is applied to UTF-8 to UTF-16 transcoding \cite{rob_u8u16, rob_u8u16_techreport}, XML parsing \cite{medforth_icxml, rob_xml} and regular expression matching \cite{rob_regex}. For these applications, byte streams of the input text characters are first transposed into 8 bit streams, one for each bit value of the character byte, and then loaded into SIMD registers so that 128 or 256 consecutive code units can be processed at once \cite{inductive_doubling_principle}. SIMD bitwise logic, shift operations, bit scans and other bit-based lies the foundation of this programming model.

With parallel bit streams, UTF-8 to UTF-16 transcoding achieves a 3X to 25X speed-up, XML well-formedness checking achieves an overall 3X to 10X performance improvement \cite{inductive_doubling_principle} and the recent regular expression matching even achieves 5X to more than 100X speed-up against the widely used tools for some regular expression \cite{rob_regex}. To get these great performance achievement, the Parabix tool chain needs to handle SIMD programming carefully and it is a challenging work for the following two major reasons:

\begin{enumerate}
  \item SIMD instruction sets varies greatly among different architectures which makes it hard to write portable SIMD programs. Some operations in Intel SSE2 may not exist in PowerPC AltiVec.
  \item Even within one specific SIMD instruction set, due to the limitation of the existing architecture and the cost of redesigning, the instruction may be only available for some pre-chosen data sizes. This is referred as "sparse instruction set" in \cite{hybrid_simd_type_legalize} and they gave a good example: in Intel SSE4, to shift-left an vector was implemented, but to shift-right was not. The 32-bit and 16-bit shift operations were available, but 64-bit shift was not \cite{hybrid_simd_type_legalize}.
\end{enumerate}

Current Parabix tool chain introduces the Inductive Doubling Instruction Set Architecture (IDISA) as an ideal computing model to overcome these two difficulties. Based on this model a library with the same name has been developed and given a set of hardware intrinsics and a pool of strategies, IDISA could choose the best implementation of each SIMD operation in terms of a cost model. It works well, but still has two shortcomings:

\begin{enumerate}
  \item IDISA has to implement different header files for different architectures. Although it has the uniform API interface that grants portability, we still needs to maintain target-specific implementation details which require a deep understanding of such target.
  \item IDISA chooses the best implementation within the scope of a single function which may be not the best when considering the context of this function. For example, we may know all the high bits of each field in a SIMD register is zero, thus additions on this register can be simplified.
\end{enumerate}

This motivates us to find a better backend and currently, the most promising backend framework is the LLVM, which promises to enable out-sourcing of low-level and target-specific aspects of code generation \cite{llvm_ghc, chris_msthesis}. Switching to LLVM backend would benefit Parabix tool chain for the following:

\begin{enumerate}
  \item LLVM provides a target-independent intermediate representation (IR) as its virtual instruction set and all Parabix operations can be expressed with IR and ported to any platform that LLVM supports, including X86, ARM, PowerPC, MIPS, SPARC and many more.
  \item LLVM provides inter-procedural, life-long program analysis and optimization \cite{llvm_cgo04}. By built-in type system in the low level representation, LLVM keeps more static information to the backend and help optimize Parabix operation with meaningful context.
  \item LLVM provides just-in-time compilation which allows runtime source generation and is critical to regular expression matching, which would like to generate sequence of Parabix operations on the fly according to the input regular expression.
\end{enumerate}

However, the native backend of LLVM does not support parallel bit streams very well. Important SIMD type of 2-bit and 4-bit field width are not available and 1-bit field width is supported slowly. Packing high bits on 16-bit field width which is one of the four key elements in the IDISA model and critical for transposition does not lower to proper machine code on X86. In this thesis, we extend LLVM to systematically support parallel bit streams. We make the following contributions:

\begin{itemize}
  \item We redefine type legality in LLVM and extend LLVM type system so that vectors of small element type get properly supported.
  \item We insert logic in the LLVM backend to recognize and handle Parabix operations to have efficient code generation while keeping the whole source code in target-independent IR.
  \item We evaluate the new LLVM backend with both micro benchmarks on single Parabix operation and application level profile. We get the performance on X86 platform as good as the well-tuned IDISA library.
\end{itemize}

The remainder of this thesis is organized as follows. In Chapter~\ref{two}, we will give a quick background of parallel bit streams and LLVM\@. Then we talk about how we are going to back parallel bit steams with LLVM and some of the design objectives in Chapter~\ref{three}. Algorithms for the actual code generation will be discussed in Chapter~\ref{four} and the implementation details in Chapter~\ref{five}. We demonstrate performance evaluation in the Chapter~\ref{six} to validate our algorithms and we come to our conclusions in Chapter~\ref{seven}.


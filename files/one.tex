%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%       Chapter 1
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}
\label{one}

Nowadays Single Instruction Multiple Data (SIMD) instructions are broadly built in for most commodity processors. Compared with the traditional Single Instruction Single Data (SISD) instructions, SIMD provides an intra-register form of parallel computing by performing the same operation on many elements at the same time \cite{Fisher_phd}. SIMD instructions are widely used for multimedia processing, digital signal processing or other compute-intensive applications \cite{multimedia_simd, dsp_simd}.

The recent method of parallel bit streams (Parabix) accelerates text processing using SIMD instructions, in applications such as UTF-8 to UTF-16 transcoding \cite{rob_u8u16, rob_u8u16_techreport}, XML parsing \cite{medforth_icxml, rob_xml} and regular expression matching \cite{rob_regex}. For these applications, byte streams of the input text characters are first transposed into 8 bit streams, one for each bit value of the character byte, and then loaded into SIMD registers so that 128 or 256 consecutive code units can be processed at once \cite{inductive_doubling_principle}. SIMD bitwise logic, shift operations, bit scans and other bit-based operations form the foundation of this programming model.

Although Parabix applications achieve substantial acceleration compared to sequential (SISD) equivalents, the Parabix tool chain needs to handle SIMD programming carefully. It is challenging for the following two major reasons:

\begin{enumerate}
  \item SIMD instruction varies greatly among different instruction-set architectures (ISAs) which makes it hard to write portable SIMD programs. Some operations in Intel SSE may not exist in PowerPC AltiVec and vice versa. For example, integer comparison intrinsic $pcmpgtq$ in SSE4 does not have correspondence in PowerPC AltiVec.
  \item Even within one specific SIMD instruction set, most operations are only available for some pre-chosen data sizes. This is referred as "sparse instruction set" in \cite{hybrid_simd_type_legalize} and they gave a good example: in Intel SSE4, to shift-left a vector was implemented, but to shift-right was not. The 32-bit and 16-bit shift operations were available, but 64-bit shift was not \cite{hybrid_simd_type_legalize}.
\end{enumerate}

The current Parabix tool chain uses the Inductive Doubling Instruction Set Architecture (IDISA) as an idealized computing model to overcome these two difficulties. Based on this model a library with the same name has been developed. It works well, but still has two shortcomings:

\begin{enumerate}
  \item IDISA requires different header files for different architectures. Although it has a uniform API for portability, each header depends heavily on target-specific implementation details to provide the best implementation of each operation.
  \item The IDISA generator \cite{hua_idisa} chooses the best implementation within the scope of a single function. This may be not the best when considering the context of this function. For example, when performing addition, we may know all the high bits of each field in a SIMD register is zero, making simplification possible.
\end{enumerate}

This motivates us to find a better back end and currently, the most promising back end framework is LLVM\@. LLVM promises to enable out-sourcing of low-level and target-specific aspects of code generation \cite{llvm_ghc, chris_msthesis}. Switching to LLVM back end benefits Parabix tool chain for the following:

\begin{enumerate}
  \item LLVM provides a target-independent intermediate representation (IR) with a vector-of-integer type system that matches IDISA requirement closely. Parabix operations can be expressed with IR and hence can be ported, in principle, to any platform that LLVM supports, including X86, ARM, PowerPC, MIPS, SPARC and many more.
  \item LLVM provides inter-procedural, whole program analysis and optimization \cite{llvm_cgo04}. By built-in type system in the low level representation, LLVM keeps more static information to the back end and help optimize Parabix operation with meaningful context.
  \item LLVM provides just-in-time compilation which allows runtime source generation. This is critical to some applications such as regular expression matching, which generates sequence of Parabix operations on the fly according to the input regular expression.
\end{enumerate}

However, the native back end of LLVM has a number of gaps in its support for parallel bit streams. SIMD support for 2-bit and 4-bit field width are not available; 1-bit field width is supported slowly. Packing high bits on 16-bit field width which is one of the four key elements in the IDISA model and critical for transposition does not lower to proper machine code on X86. In this thesis, we extend LLVM to systematically support parallel bit streams and achieve high-performance code generation on the X86 target. We make the following contributions:

\begin{itemize}
  \item We port the critical Parabix operations to the LLVM back end thus bringing all the benefit of LLVM discussed above into the Parabix technology.
  \item We redefine type legality in LLVM and extend LLVM type system with the inductive doubling principle so that vectors of small element type are properly supported.
  \item We insert logic in the LLVM back end to recognize and handle key Parabix operations. This allows efficient code generation while keeping the whole source code in target-independent IR\@.
  \item We add a dedicated LLVM intrinsic for the long stream addition and enable high-performance chained addition on the unbounded integer model which can be applied in broader applications.
  \item We evaluate the new LLVM back end with both micro benchmarks on single Parabix operation and application level profiles. We get the performance on X86 platform as good as the well-tuned IDISA library.
\end{itemize}

The remainder of this thesis is organized as follows. Chapter~\ref{two} provides a quick review of Parabix and LLVM\@. Chapter~\ref{three} shows the overall design goal; examples of the IR implementation are presented and compared with the IDISA library. Algorithms for machine code generation is discussed in Chapter~\ref{four} and the implementation details is in Chapter~\ref{five}. Chapter~\ref{six} evaluates our work with both per-instruction benchmarks and application level profiles. Chapter~\ref{seven} gives the conclusion.

